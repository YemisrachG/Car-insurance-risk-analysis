{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b729d53-d2e8-4d59-9ec2-23b786b204ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b729d53-d2e8-4d59-9ec2-23b786b204ae",
    "outputId": "9adfed9c-2625-4336-d75e-35a68e82b249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shap\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ehW4nvaJnHz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ehW4nvaJnHz",
    "outputId": "31ebaa8f-7b5a-4c97-f405-4fd4a389cc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (1000098, 52)\n",
      "Data shape after initial categorical imputation: (1000098, 57)\n",
      "Data shape after dropping rows with NaN in critical targets: (1000098, 57)\n",
      "Data preparation for predictive modeling complete. Head of data with new metrics:\n",
      "   TotalPremium  TotalClaims  HasClaim  ClaimSeverity      Margin\n",
      "0     21.929825          0.0         0            NaN   21.929825\n",
      "1     21.929825          0.0         0            NaN   21.929825\n",
      "2      0.000000          0.0         0            NaN    0.000000\n",
      "3    512.848070          0.0         0            NaN  512.848070\n",
      "4      0.000000          0.0         0            NaN    0.000000\n",
      "Shape of claim_severity_df (TotalClaims > 0): (2788, 60)\n",
      "Shape of X_severity before pipeline processing: (2788, 50)\n",
      "Shape of X_premium before pipeline processing: (1000098, 49)\n",
      "Shape of X_claim_prob before pipeline processing: (1000098, 49)\n",
      "\n",
      "Severity Preprocessor: Num features: ['Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors', 'CustomValueEstimate', 'CapitalOutstanding', 'NumberOfVehiclesInFleet', 'SumInsured', 'CalculatedPremiumPerTerm', 'ExcessSelected', 'PolicyAgeMonths', 'VehicleAgeYears', 'VehicleModelAgeYears', 'PremiumPerSumInsured', 'ClaimsPerSumInsured'], Cat features: ['IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType', 'make', 'Model', 'bodytype', 'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder', 'TermFrequency', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "Premium Preprocessor: Num features: ['Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors', 'CustomValueEstimate', 'CapitalOutstanding', 'NumberOfVehiclesInFleet', 'SumInsured', 'ExcessSelected', 'PolicyAgeMonths', 'VehicleAgeYears', 'VehicleModelAgeYears', 'PremiumPerSumInsured', 'ClaimsPerSumInsured'], Cat features: ['IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType', 'make', 'Model', 'bodytype', 'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder', 'TermFrequency', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "Claim Probability Preprocessor: Num features: ['Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors', 'CustomValueEstimate', 'CapitalOutstanding', 'NumberOfVehiclesInFleet', 'SumInsured', 'ExcessSelected', 'PolicyAgeMonths', 'VehicleAgeYears', 'VehicleModelAgeYears', 'PremiumPerSumInsured', 'ClaimsPerSumInsured'], Cat features: ['IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType', 'make', 'Model', 'bodytype', 'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder', 'TermFrequency', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "\n",
      "Data preprocessing setup complete for modeling.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/content/drive/My Drive'\n",
    "data = pd.read_csv(os.path.join(DATA_DIR, 'MachineLearningRating_v3.txt'), sep='|')\n",
    "print(f\"Initial data shape: {data.shape}\")\n",
    "\n",
    "numerical_columns_to_coerce = [\n",
    "    'TotalPremium', 'TotalClaims', 'CustomValueEstimate', 'CapitalOutstanding',\n",
    "    'Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors', 'SumInsured',\n",
    "    'CalculatedPremiumPerTerm', 'ExcessSelected', 'NumberOfVehiclesInFleet',\n",
    "    'RegistrationYear'\n",
    "]\n",
    "\n",
    "for col in numerical_columns_to_coerce:\n",
    "    if col in data.columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "current_date = pd.to_datetime('2025-06-17')\n",
    "\n",
    "if 'TransactionMonth' in data.columns:\n",
    "    data['TransactionMonth'] = pd.to_datetime(data['TransactionMonth'], errors='coerce')\n",
    "    data['PolicyAgeMonths'] = (current_date - data['TransactionMonth']).dt.days / 30.44\n",
    "else:\n",
    "    data['PolicyAgeMonths'] = np.nan\n",
    "\n",
    "if 'RegistrationYear' in data.columns:\n",
    "    data['VehicleAgeYears'] = (current_date.year - data['RegistrationYear'])\n",
    "else:\n",
    "    data['VehicleAgeYears'] = np.nan\n",
    "\n",
    "if 'VehicleIntroDate' in data.columns:\n",
    "    data['VehicleIntroDate'] = pd.to_datetime(data['VehicleIntroDate'], errors='coerce')\n",
    "    data['VehicleModelAgeYears'] = (current_date.year - data['VehicleIntroDate'].dt.year)\n",
    "else:\n",
    "    data['VehicleModelAgeYears'] = np.nan\n",
    "\n",
    "# Interaction features\n",
    "if 'TotalPremium' in data.columns and 'SumInsured' in data.columns:\n",
    "    temp_sum_insured = data['SumInsured'].replace(0, np.nan)\n",
    "    data['PremiumPerSumInsured'] = data['TotalPremium'] / temp_sum_insured\n",
    "else:\n",
    "    data['PremiumPerSumInsured'] = np.nan\n",
    "\n",
    "if 'TotalClaims' in data.columns and 'SumInsured' in data.columns:\n",
    "    temp_sum_insured = data['SumInsured'].replace(0, np.nan)\n",
    "    data['ClaimsPerSumInsured'] = data['TotalClaims'] / temp_sum_insured\n",
    "else:\n",
    "    data['ClaimsPerSumInsured'] = np.nan\n",
    "\n",
    "categorical_cols_to_impute_unknown = [\n",
    "    'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', 'Bank',\n",
    "    'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'PostalCode',\n",
    "    'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType', 'make',\n",
    "    'Model', 'bodytype', 'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle',\n",
    "    'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder', 'CoverCategory',\n",
    "    'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType',\n",
    "    'TermFrequency'\n",
    "]\n",
    "\n",
    "for col in categorical_cols_to_impute_unknown:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(str)\n",
    "        data[col] = data[col].replace('nan', 'Unknown')\n",
    "        data[col] = data[col].replace('None', 'Unknown')\n",
    "\n",
    "print(f\"Data shape after initial categorical imputation: {data.shape}\")\n",
    "\n",
    "data.dropna(subset=['TotalPremium', 'TotalClaims', 'CalculatedPremiumPerTerm'], inplace=True)\n",
    "print(f\"Data shape after dropping rows with NaN in critical targets: {data.shape}\")\n",
    "\n",
    "# Calculate HasClaim and ClaimSeverity AFTER cleaning TotalClaims\n",
    "data['HasClaim'] = (data['TotalClaims'] > 0).astype(int)\n",
    "data['ClaimSeverity'] = data.apply(lambda row: row['TotalClaims'] if row['HasClaim'] == 1 else np.nan, axis=1)\n",
    "\n",
    "# Calculate Margin\n",
    "data['Margin'] = data['TotalPremium'] - data['TotalClaims']\n",
    "\n",
    "print(\"Data preparation for predictive modeling complete. Head of data with new metrics:\")\n",
    "print(data[['TotalPremium', 'TotalClaims', 'HasClaim', 'ClaimSeverity', 'Margin']].head())\n",
    "\n",
    "# --- Separate target variables for each modeling goal ---\n",
    "columns_to_drop_for_X = [\n",
    "    'UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'VehicleIntroDate',\n",
    "    'TotalPremium', 'TotalClaims', 'Margin', 'HasClaim',\n",
    "    'RegistrationYear', 'ClaimSeverity'\n",
    "]\n",
    "\n",
    "# 1. Claim Severity Prediction (Regression on TotalClaims where claims > 0)\n",
    "claim_severity_df = data[data['TotalClaims'] > 0].copy()\n",
    "print(f\"Shape of claim_severity_df (TotalClaims > 0): {claim_severity_df.shape}\")\n",
    "\n",
    "X_severity = claim_severity_df.drop(columns=columns_to_drop_for_X, errors='ignore')\n",
    "y_severity = claim_severity_df['TotalClaims']\n",
    "\n",
    "print(f\"Shape of X_severity before pipeline processing: {X_severity.shape}\")\n",
    "# 2. Premium Optimization (Naive: Predict CalculatedPremiumPerTerm)\n",
    "premium_optimization_df = data.copy()\n",
    "X_premium = premium_optimization_df.drop(columns=columns_to_drop_for_X + ['CalculatedPremiumPerTerm'], errors='ignore')\n",
    "y_premium = premium_optimization_df['CalculatedPremiumPerTerm']\n",
    "\n",
    "print(f\"Shape of X_premium before pipeline processing: {X_premium.shape}\")\n",
    "\n",
    "# 3. Probability of Claim (Binary Classification)\n",
    "X_claim_prob = data.drop(columns=columns_to_drop_for_X + ['CalculatedPremiumPerTerm'], errors='ignore')\n",
    "y_claim_prob = data['HasClaim']\n",
    "\n",
    "print(f\"Shape of X_claim_prob before pipeline processing: {X_claim_prob.shape}\")\n",
    "\n",
    "# --- Train-Test Split (with checks for sufficient data) ---\n",
    "X_train_severity, X_test_severity, y_train_severity, y_test_severity = pd.DataFrame(), pd.DataFrame(), pd.Series(), pd.Series()\n",
    "X_train_premium, X_test_premium, y_train_premium, y_test_premium = pd.DataFrame(), pd.DataFrame(), pd.Series(), pd.Series()\n",
    "X_train_claim_prob, X_test_claim_prob, y_train_claim_prob, y_test_claim_prob = pd.DataFrame(), pd.DataFrame(), pd.Series(), pd.Series()\n",
    "\n",
    "\n",
    "if not y_severity.empty and len(X_severity) > 1:\n",
    "    X_train_severity, X_test_severity, y_train_severity, y_test_severity = train_test_split(X_severity, y_severity, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Warning: Insufficient data for Claim Severity Prediction after NaN removal. Skipping split.\")\n",
    "\n",
    "if not y_premium.empty and len(X_premium) > 1:\n",
    "    X_train_premium, X_test_premium, y_train_premium, y_test_premium = train_test_split(X_premium, y_premium, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Warning: Insufficient data for Premium Optimization after NaN removal. Skipping split.\")\n",
    "\n",
    "if not y_claim_prob.empty and len(X_claim_prob) > 1:\n",
    "    if y_claim_prob.nunique() > 1:\n",
    "        X_train_claim_prob, X_test_claim_prob, y_train_claim_prob, y_test_claim_prob = train_test_split(X_claim_prob, y_claim_prob, test_size=0.2, random_state=42, stratify=y_claim_prob)\n",
    "    else:\n",
    "        print(\"Warning: Only one class present for Claim Probability after NaN removal. Cannot stratify. Splitting without stratification.\")\n",
    "        X_train_claim_prob, X_test_claim_prob, y_train_claim_prob, y_test_claim_prob = train_test_split(X_claim_prob, y_claim_prob, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Warning: Insufficient data for Claim Probability Prediction after NaN removal. Skipping split.\")\n",
    "\n",
    "\n",
    "# --- Create preprocessing pipelines for numerical and categorical features ---\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # Imputes NaNs with the median of the training data\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')), # Imputes NaNs/missing categories with 'Unknown'\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Preprocessor for Severity Model\n",
    "if not X_train_severity.empty:\n",
    "    numerical_features_severity = X_train_severity.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features_severity = X_train_severity.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "    preprocessor_severity = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features_severity),\n",
    "            ('cat', categorical_transformer, categorical_features_severity)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    print(f\"\\nSeverity Preprocessor: Num features: {numerical_features_severity}, Cat features: {categorical_features_severity}\")\n",
    "else:\n",
    "    preprocessor_severity = None\n",
    "    print(\"Severity preprocessor not created due to insufficient training data.\")\n",
    "\n",
    "\n",
    "# Preprocessor for Premium Model\n",
    "if not X_train_premium.empty:\n",
    "    numerical_features_premium = X_train_premium.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features_premium = X_train_premium.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "    preprocessor_premium = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features_premium),\n",
    "            ('cat', categorical_transformer, categorical_features_premium)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    print(f\"Premium Preprocessor: Num features: {numerical_features_premium}, Cat features: {categorical_features_premium}\")\n",
    "else:\n",
    "    preprocessor_premium = None\n",
    "    print(\"Premium preprocessor not created due to insufficient training data.\")\n",
    "\n",
    "\n",
    "# Preprocessor for Claim Probability Model\n",
    "if not X_train_claim_prob.empty:\n",
    "    numerical_features_claim_prob = X_train_claim_prob.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features_claim_prob = X_train_claim_prob.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "    preprocessor_claim_prob = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features_claim_prob),\n",
    "            ('cat', categorical_transformer, categorical_features_claim_prob)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    print(f\"Claim Probability Preprocessor: Num features: {numerical_features_claim_prob}, Cat features: {categorical_features_claim_prob}\")\n",
    "else:\n",
    "    preprocessor_claim_prob = None\n",
    "    print(\"Claim probability preprocessor not created due to insufficient training data.\")\n",
    "\n",
    "print(\"\\nData preprocessing setup complete for modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1hNdsG8oJptN",
   "metadata": {
    "id": "1hNdsG8oJptN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Un6k1yPHEXds",
   "metadata": {
    "id": "Un6k1yPHEXds"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf61ff0-58db-4119-9395-29dc06d47667",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cf61ff0-58db-4119-9395-29dc06d47667",
    "outputId": "7e205ee6-8063-4766-81bd-5301dd426cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Claim Severity Prediction Models ---\n",
      "\n",
      "Training Linear Regression for Claim Severity...\n",
      "Linear Regression - RMSE: 38377.20, R-squared: 0.08\n",
      "\n",
      "Training Random Forest for Claim Severity...\n",
      "Random Forest - RMSE: 7866.83, R-squared: 0.96\n",
      "\n",
      "Training XGBoost for Claim Severity...\n",
      "XGBoost - RMSE: 7904.32, R-squared: 0.96\n",
      "\n",
      "--- Claim Severity Model Evaluation Summary ---\n",
      "Linear Regression: RMSE=38377.20, R2=0.08\n",
      "Random Forest: RMSE=7866.83, R2=0.96\n",
      "XGBoost: RMSE=7904.32, R2=0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Claim Severity Prediction Models ---\")\n",
    "\n",
    "models_severity = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "results_severity = {}\n",
    "\n",
    "for name, model in models_severity.items():\n",
    "    print(f\"\\nTraining {name} for Claim Severity...\")\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor_severity),\n",
    "                               ('regressor', model)])\n",
    "    pipeline.fit(X_train_severity, y_train_severity)\n",
    "    y_pred_severity = pipeline.predict(X_test_severity)\n",
    "\n",
    "    rmse_severity = np.sqrt(mean_squared_error(y_test_severity, y_pred_severity))\n",
    "    r2_severity = r2_score(y_test_severity, y_pred_severity)\n",
    "\n",
    "    results_severity[name] = {'RMSE': rmse_severity, 'R2': r2_severity}\n",
    "    print(f\"{name} - RMSE: {rmse_severity:.2f}, R-squared: {r2_severity:.2f}\")\n",
    "    if name == 'XGBoost': \n",
    "        best_model_severity_pipeline = pipeline\n",
    "        best_model_severity_name = name\n",
    "\n",
    "print(\"\\n--- Claim Severity Model Evaluation Summary ---\")\n",
    "for name, metrics in results_severity.items():\n",
    "    print(f\"{name}: RMSE={metrics['RMSE']:.2f}, R2={metrics['R2']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb700270-1d69-4f66-a1cf-537f6a3692eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb700270-1d69-4f66-a1cf-537f6a3692eb",
    "outputId": "024f27ce-4b90-41c8-9a49-19af34964614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Premium Optimization (Predicting CalculatedPremiumPerTerm) Models ---\n",
      "\n",
      "Training Linear Regression for Premium Prediction...\n",
      "Linear Regression - RMSE: 208.27, R-squared: 0.46\n",
      "\n",
      "Training Random Forest for Premium Prediction...\n",
      "Random Forest - RMSE: 12.53, R-squared: 1.00\n",
      "\n",
      "Training XGBoost for Premium Prediction...\n",
      "XGBoost - RMSE: 25.99, R-squared: 0.99\n",
      "\n",
      "--- Premium Prediction Model Evaluation Summary ---\n",
      "Linear Regression: RMSE=208.27, R2=0.46\n",
      "Random Forest: RMSE=12.53, R2=1.00\n",
      "XGBoost: RMSE=25.99, R2=0.99\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Premium Optimization (Predicting CalculatedPremiumPerTerm) Models ---\")\n",
    "\n",
    "models_premium = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=10),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "results_premium = {}\n",
    "\n",
    "for name, model in models_premium.items():\n",
    "    print(f\"\\nTraining {name} for Premium Prediction...\")\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor_premium),\n",
    "                               ('regressor', model)])\n",
    "    pipeline.fit(X_train_premium, y_train_premium)\n",
    "    y_pred_premium = pipeline.predict(X_test_premium)\n",
    "\n",
    "    rmse_premium = np.sqrt(mean_squared_error(y_test_premium, y_pred_premium))\n",
    "    r2_premium = r2_score(y_test_premium, y_pred_premium)\n",
    "\n",
    "    results_premium[name] = {'RMSE': rmse_premium, 'R2': r2_premium}\n",
    "    print(f\"{name} - RMSE: {rmse_premium:.2f}, R-squared: {r2_premium:.2f}\")\n",
    "\n",
    "    if name == 'XGBoost':\n",
    "        best_model_premium_pipeline = pipeline\n",
    "        best_model_premium_name = name\n",
    "\n",
    "print(\"\\n--- Premium Prediction Model Evaluation Summary ---\")\n",
    "for name, metrics in results_premium.items():\n",
    "    print(f\"{name}: RMSE={metrics['RMSE']:.2f}, R2={metrics['R2']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
