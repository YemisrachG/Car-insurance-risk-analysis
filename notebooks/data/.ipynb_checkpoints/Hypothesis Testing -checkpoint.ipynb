{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aece15aa-1def-40f3-b3eb-54c19067349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Claim Frequency by Province ---\n",
      "Chi-squared test for Claim Frequency by Province: p-value = 0.0000\n",
      "There are statistically significant differences in claim frequency across provinces.\n",
      "\n",
      "Claim Frequency by Province:\n",
      "Province\n",
      "Gauteng          0.003388\n",
      "KwaZulu-Natal    0.002874\n",
      "Limpopo          0.002698\n",
      "North West       0.002436\n",
      "Mpumalanga       0.002428\n",
      "Western Cape     0.002166\n",
      "Eastern Cape     0.001648\n",
      "Free State       0.001358\n",
      "Northern Cape    0.001254\n",
      "Name: HasClaim, dtype: float64\n",
      "Interpretation: Provinces like Gauteng show a higher claim frequency compared to others, such as Northern Cape.\n",
      "\n",
      "--- Claim Severity by Province (for policies with claims) ---\n",
      "ANOVA test for Claim Severity by Province: p-value = 0.0000\n",
      "Reject H0. There are statistically significant differences in claim severity across provinces.\n",
      "\n",
      "Average Claim Severity by Province:\n",
      "Province\n",
      "Free State       32265.661085\n",
      "KwaZulu-Natal    29609.487473\n",
      "Western Cape     28095.849881\n",
      "Eastern Cape     27128.533277\n",
      "Gauteng          22094.735590\n",
      "North West       16963.467035\n",
      "Mpumalanga       15979.553421\n",
      "Limpopo          15171.294187\n",
      "Northern Cape    11186.313596\n",
      "Name: ClaimSeverity, dtype: float64\n",
      "Interpretation: Policies in Free State tend to have higher average claim amounts when a claim occurs, compared to Northern Cape.\n",
      "\n",
      "--- Testing H0: No risk differences between zip codes ---\n",
      "\n",
      "--- Claim Frequency by Top N Postal Codes ---\n",
      "Chi-squared test for Claim Frequency by Top N Postal Codes: p-value = 0.0000\n",
      "Conclusion: Reject H0. There are statistically significant differences in claim frequency across these top zip codes.\n",
      "\n",
      "Claim Frequency by Top N Postal Codes:\n",
      "PostalCode\n",
      "8000    0.004324\n",
      "470     0.004303\n",
      "122     0.004271\n",
      "2000    0.003641\n",
      "7100    0.002756\n",
      "299     0.002623\n",
      "1724    0.002474\n",
      "458     0.002323\n",
      "7784    0.001749\n",
      "7405    0.001566\n",
      "Name: HasClaim, dtype: float64\n",
      "Interpretation: Some zip codes (8000 e.g.) show a higher propensity for claims.\n",
      "\n",
      "--- Claim Severity by Top N Postal Codes (for policies with claims) ---\n",
      "ANOVA test for Claim Severity by Top N Postal Codes: p-value = 0.0022\n",
      "Conclusion: Reject H0. There are statistically significant differences in claim severity across these top zip codes.\n",
      "\n",
      "Average Claim Severity by Top N Postal Codes:\n",
      "PostalCode\n",
      "7784    35156.653709\n",
      "8000    33685.329976\n",
      "1724    22034.356842\n",
      "7100    21165.158246\n",
      "7405    21002.022686\n",
      "458     20160.273246\n",
      "2000    19196.413727\n",
      "122     18162.025865\n",
      "299     13622.745632\n",
      "470     12946.833234\n",
      "Name: ClaimSeverity, dtype: float64\n",
      "Interpretation: Certain zip codes (7784 e.g.) are associated with higher average claim costs when claims occur.\n",
      "\n",
      "--- Testing H0: No significant margin (profit) difference between zip codes ---\n",
      "ANOVA test for Margin by Top N Postal Codes: p-value = 0.3108\n",
      "Conclusion: Fail to reject H0. No statistically significant differences in margin across these top zip codes.\n",
      "\n",
      "--- Testing H0: No significant risk difference between Women and Men ---\n",
      "\n",
      "--- Claim Frequency by Gender ---\n",
      "Chi-squared test for Claim Frequency by Gender: p-value = 0.0266\n",
      "Conclusion: Reject H0. There are statistically significant differences in claim frequency between genders.\n",
      "\n",
      "Claim Frequency by Gender:\n",
      "Gender\n",
      "Not specified    0.002833\n",
      "Male             0.002195\n",
      "Female           0.002073\n",
      "Name: HasClaim, dtype: float64\n",
      "Interpretation: Not specified show a higher claim frequency compared to Male.\n",
      "\n",
      "--- Claim Severity by Gender (for policies with claims) ---\n",
      "Independent t-test for Claim Severity by Gender: p-value = 0.5680\n",
      "Conclusion: Fail to reject H0. No statistically significant differences in claim severity between genders.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "os.chdir(r'C:\\Wk 3 Car Insurance Risk & Marketing Analytics\\Car-insurance-risk-analysis')\n",
    "\n",
    "sys.path.append(os.getcwd()) \n",
    "\n",
    "\n",
    "DATA_DIR = 'notebooks/data'\n",
    "data = pd.read_csv(os.path.join(DATA_DIR, 'MachineLearningRating_v3.txt'), sep='|')\n",
    "\n",
    "data['TotalPremium'] = pd.to_numeric(data['TotalPremium'], errors='coerce')\n",
    "data['TotalClaims'] = pd.to_numeric(data['TotalClaims'], errors='coerce')\n",
    "\n",
    "data.dropna(subset=['TotalPremium', 'TotalClaims', 'Province', 'Gender', 'PostalCode'], inplace=True)\n",
    "\n",
    "data['HasClaim'] = (data['TotalClaims'] > 0).astype(int)\n",
    "\n",
    "data['ClaimSeverity'] = data.apply(lambda row: row['TotalClaims'] if row['HasClaim'] == 1 else np.nan, axis=1)\n",
    "\n",
    "data['Margin'] = data['TotalPremium'] - data['TotalClaims']\n",
    "\n",
    "## H0: There are no risk differences across provinces\n",
    "\n",
    "# Data segmentation by Province\n",
    "provinces = data['Province'].unique()\n",
    "\n",
    "print(\"\\n--- Claim Frequency by Province ---\")\n",
    "claim_province_crosstab = pd.crosstab(data['Province'], data['HasClaim'])\n",
    "\n",
    "if claim_province_crosstab.shape[0] > 1 and claim_province_crosstab.shape[1] > 1 and (claim_province_crosstab > 0).all().all():\n",
    "    chi2, p_value_freq, _, _ = stats.chi2_contingency(claim_province_crosstab)\n",
    "    print(f\"Chi-squared test for Claim Frequency by Province: p-value = {p_value_freq:.4f}\")\n",
    "    if p_value_freq < 0.05:\n",
    "        print(\"There are statistically significant differences in claim frequency across provinces.\")\n",
    "      \n",
    "        province_claim_frequency = data.groupby('Province')['HasClaim'].mean().sort_values(ascending=False)\n",
    "        print(\"\\nClaim Frequency by Province:\")\n",
    "        print(province_claim_frequency)\n",
    "        print(f\"Interpretation: Provinces like {province_claim_frequency.index[0]} show a higher claim frequency compared to others, such as {province_claim_frequency.index[-1]}.\")\n",
    "    else:\n",
    "        print(\"Fail to reject H0. No statistically significant differences in claim frequency across provinces.\")\n",
    "else:\n",
    "    print(\"Cannot perform Chi-squared test due to insufficient data or all zero values in contingency table.\")\n",
    "\n",
    "print(\"\\n--- Claim Severity by Province (for policies with claims) ---\")\n",
    "# Filter for policies with claims for severity analysis\n",
    "claim_severity_data = data[data['HasClaim'] == 1].dropna(subset=['ClaimSeverity', 'Province'])\n",
    "\n",
    "if len(claim_severity_data['Province'].unique()) > 1:\n",
    "    groups = [claim_severity_data['ClaimSeverity'][claim_severity_data['Province'] == p] for p in claim_severity_data['Province'].unique()]\n",
    "    groups = [g for g in groups if not g.empty]\n",
    "\n",
    "    if len(groups) > 1:\n",
    "        f_stat_severity, p_value_severity = stats.f_oneway(*groups)\n",
    "        print(f\"ANOVA test for Claim Severity by Province: p-value = {p_value_severity:.4f}\")\n",
    "        if p_value_severity < 0.05:\n",
    "            print(\"Reject H0. There are statistically significant differences in claim severity across provinces.\")\n",
    "            # Interpretation\n",
    "            province_claim_severity = claim_severity_data.groupby('Province')['ClaimSeverity'].mean().sort_values(ascending=False)\n",
    "            print(\"\\nAverage Claim Severity by Province:\")\n",
    "            print(province_claim_severity)\n",
    "            print(f\"Interpretation: Policies in {province_claim_severity.index[0]} tend to have higher average claim amounts when a claim occurs, compared to {province_claim_severity.index[-1]}.\")\n",
    "        else:\n",
    "            print(\"Fail to reject H0. No statistically significant differences in claim severity across provinces.\")\n",
    "    else:\n",
    "        print(\"Cannot perform ANOVA: Not enough distinct provinces with claims data.\")\n",
    "else:\n",
    "    print(\"Cannot perform ANOVA: Only one province found with claim severity data.\")\n",
    "print(\"\\n--- Testing H0: No risk differences between zip codes ---\")\n",
    "\n",
    "# To make this manageable, let's consider a subset of top N most frequent PostalCodes\n",
    "top_n_zip_codes = data['PostalCode'].value_counts().nlargest(10).index.tolist()\n",
    "data_top_zips = data[data['PostalCode'].isin(top_n_zip_codes)].copy()\n",
    "\n",
    "if not data_top_zips.empty and len(data_top_zips['PostalCode'].unique()) > 1:\n",
    "    print(\"\\n--- Claim Frequency by Top N Postal Codes ---\")\n",
    "    claim_zip_crosstab = pd.crosstab(data_top_zips['PostalCode'], data_top_zips['HasClaim'])\n",
    "    if claim_zip_crosstab.shape[0] > 1 and claim_zip_crosstab.shape[1] > 1 and (claim_zip_crosstab > 0).all().all():\n",
    "        chi2_zip_freq, p_value_zip_freq, _, _ = stats.chi2_contingency(claim_zip_crosstab)\n",
    "        print(f\"Chi-squared test for Claim Frequency by Top N Postal Codes: p-value = {p_value_zip_freq:.4f}\")\n",
    "        if p_value_zip_freq < 0.05:\n",
    "            print(\"Conclusion: Reject H0. There are statistically significant differences in claim frequency across these top zip codes.\")\n",
    "            # Interpretation\n",
    "            zip_claim_frequency = data_top_zips.groupby('PostalCode')['HasClaim'].mean().sort_values(ascending=False)\n",
    "            print(\"\\nClaim Frequency by Top N Postal Codes:\")\n",
    "            print(zip_claim_frequency)\n",
    "            print(f\"Interpretation: Some zip codes ({zip_claim_frequency.index[0]} e.g.) show a higher propensity for claims.\")\n",
    "        else:\n",
    "            print(\"Conclusion: Fail to reject H0. No statistically significant differences in claim frequency across these top zip codes.\")\n",
    "    else:\n",
    "        print(\"Cannot perform Chi-squared test for top N zip codes due to insufficient data or all zero values.\")\n",
    "\n",
    "    # --- Test for Claim Severity by Top N PostalCodes (ANOVA) ---\n",
    "    print(\"\\n--- Claim Severity by Top N Postal Codes (for policies with claims) ---\")\n",
    "    claim_severity_data_top_zips = data_top_zips[data_top_zips['HasClaim'] == 1].dropna(subset=['ClaimSeverity', 'PostalCode'])\n",
    "\n",
    "    if len(claim_severity_data_top_zips['PostalCode'].unique()) > 1:\n",
    "        groups_zip_severity = [claim_severity_data_top_zips['ClaimSeverity'][claim_severity_data_top_zips['PostalCode'] == z] for z in claim_severity_data_top_zips['PostalCode'].unique()]\n",
    "        groups_zip_severity = [g for g in groups_zip_severity if not g.empty]\n",
    "\n",
    "        if len(groups_zip_severity) > 1:\n",
    "            f_stat_zip_severity, p_value_zip_severity = stats.f_oneway(*groups_zip_severity)\n",
    "            print(f\"ANOVA test for Claim Severity by Top N Postal Codes: p-value = {p_value_zip_severity:.4f}\")\n",
    "            if p_value_zip_severity < 0.05:\n",
    "                print(\"Conclusion: Reject H0. There are statistically significant differences in claim severity across these top zip codes.\")\n",
    "                # Interpretation\n",
    "                zip_claim_severity = claim_severity_data_top_zips.groupby('PostalCode')['ClaimSeverity'].mean().sort_values(ascending=False)\n",
    "                print(\"\\nAverage Claim Severity by Top N Postal Codes:\")\n",
    "                print(zip_claim_severity)\n",
    "                print(f\"Interpretation: Certain zip codes ({zip_claim_severity.index[0]} e.g.) are associated with higher average claim costs when claims occur.\")\n",
    "            else:\n",
    "                print(\"Fail to reject H0. No statistically significant differences in claim severity across these top zip codes.\")\n",
    "        else:\n",
    "            print(\"Cannot perform ANOVA for top N zip codes: Not enough distinct zip codes with claims data.\")\n",
    "    else:\n",
    "        print(\"Cannot perform ANOVA for top N zip codes: Only one postal code found with claim severity data.\")\n",
    "else:\n",
    "    print(\"Insufficient data or only one unique postal code among top N for testing risk differences between zip codes.\")\n",
    "\n",
    "print(\"\\n--- Testing H0: No significant margin (profit) difference between zip codes ---\")\n",
    "margin_data_top_zips = data_top_zips.dropna(subset=['Margin', 'PostalCode'])\n",
    "\n",
    "if len(margin_data_top_zips['PostalCode'].unique()) > 1:\n",
    "    groups_zip_margin = [margin_data_top_zips['Margin'][margin_data_top_zips['PostalCode'] == z] for z in margin_data_top_zips['PostalCode'].unique()]\n",
    "    groups_zip_margin = [g for g in groups_zip_margin if not g.empty]\n",
    "\n",
    "    if len(groups_zip_margin) > 1:\n",
    "        f_stat_zip_margin, p_value_zip_margin = stats.f_oneway(*groups_zip_margin)\n",
    "        print(f\"ANOVA test for Margin by Top N Postal Codes: p-value = {p_value_zip_margin:.4f}\")\n",
    "        if p_value_zip_margin < 0.05:\n",
    "            print(\"Conclusion: Reject H0. There are statistically significant differences in margin across these top zip codes.\")\n",
    "            # Interpretation\n",
    "            zip_margin = margin_data_top_zips.groupby('PostalCode')['Margin'].mean().sort_values(ascending=False)\n",
    "            print(\"\\nAverage Margin by Top N Postal Codes:\")\n",
    "            print(zip_margin)\n",
    "            print(f\"Interpretation: Certain zip codes ({zip_margin.index[0]} e.g.) yield significantly higher profit margins, suggesting opportunities for targeted marketing or premium adjustments.\")\n",
    "        else:\n",
    "            print(\"Conclusion: Fail to reject H0. No statistically significant differences in margin across these top zip codes.\")\n",
    "    else:\n",
    "        print(\"Cannot perform ANOVA for top N zip codes: Not enough distinct zip codes with margin data.\")\n",
    "else:\n",
    "    print(\"Insufficient data or only one unique postal code among top N for testing margin differences between zip codes.\")\n",
    "print(\"\\n--- Testing H0: No significant risk difference between Women and Men ---\")\n",
    "\n",
    "# Data segmentation by Gender\n",
    "genders = data['Gender'].unique()\n",
    "if 'Male' in genders and 'Female' in genders: # Ensure both genders are present\n",
    "    print(\"\\n--- Claim Frequency by Gender ---\")\n",
    "    claim_gender_crosstab = pd.crosstab(data['Gender'], data['HasClaim'])\n",
    "    if claim_gender_crosstab.shape[0] > 1 and claim_gender_crosstab.shape[1] > 1 and (claim_gender_crosstab > 0).all().all():\n",
    "        chi2_gender_freq, p_value_gender_freq, _, _ = stats.chi2_contingency(claim_gender_crosstab)\n",
    "        print(f\"Chi-squared test for Claim Frequency by Gender: p-value = {p_value_gender_freq:.4f}\")\n",
    "        if p_value_gender_freq < 0.05:\n",
    "            print(\"Conclusion: Reject H0. There are statistically significant differences in claim frequency between genders.\")\n",
    "            gender_claim_frequency = data.groupby('Gender')['HasClaim'].mean().sort_values(ascending=False)\n",
    "            print(\"\\nClaim Frequency by Gender:\")\n",
    "            print(gender_claim_frequency)\n",
    "            print(f\"Interpretation: {gender_claim_frequency.index[0]} show a higher claim frequency compared to {gender_claim_frequency.index[1]}.\")\n",
    "        else:\n",
    "            print(\"Fail to reject H0. No statistically significant differences in claim frequency between genders.\")\n",
    "    else:\n",
    "        print(\"Cannot perform Chi-squared test for gender due to insufficient data or all zero values.\")\n",
    "    print(\"\\n--- Claim Severity by Gender (for policies with claims) ---\")\n",
    "    claim_severity_data_gender = data[data['HasClaim'] == 1].dropna(subset=['ClaimSeverity', 'Gender'])\n",
    "\n",
    "    if 'Male' in claim_severity_data_gender['Gender'].unique() and 'Female' in claim_severity_data_gender['Gender'].unique():\n",
    "        male_claims = claim_severity_data_gender[claim_severity_data_gender['Gender'] == 'Male']['ClaimSeverity']\n",
    "        female_claims = claim_severity_data_gender[claim_severity_data_gender['Gender'] == 'Female']['ClaimSeverity']\n",
    "\n",
    "        if not male_claims.empty and not female_claims.empty:\n",
    "            t_stat_gender_severity, p_value_gender_severity = stats.ttest_ind(male_claims, female_claims, equal_var=False) # Welch's t-test assuming unequal variances\n",
    "            print(f\"Independent t-test for Claim Severity by Gender: p-value = {p_value_gender_severity:.4f}\")\n",
    "            if p_value_gender_severity < 0.05:\n",
    "                print(\"Conclusion: Reject H0. There are statistically significant differences in claim severity between genders.\")\n",
    "               \n",
    "                gender_claim_severity = claim_severity_data_gender.groupby('Gender')['ClaimSeverity'].mean().sort_values(ascending=False)\n",
    "                print(\"\\nAverage Claim Severity by Gender:\")\n",
    "                print(gender_claim_severity)\n",
    "                print(f\"Interpretation: When claims occur, {gender_claim_severity.index[0]} tend to have higher average claim amounts than {gender_claim_severity.index[1]}.\")\n",
    "            else:\n",
    "                print(\"Conclusion: Fail to reject H0. No statistically significant differences in claim severity between genders.\")\n",
    "        else:\n",
    "            print(\"Cannot perform t-test for gender severity: One or both gender groups have no claim severity data.\")\n",
    "    else:\n",
    "        print(\"Cannot perform t-test for gender severity: Not enough distinct genders with claim severity data (requires Male and Female).\")\n",
    "else:\n",
    "    print(\"Cannot perform gender-based hypothesis testing: 'Male' and/or 'Female' gender categories not found in data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252d9b3-608e-45e9-a3c8-a341244d7380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
